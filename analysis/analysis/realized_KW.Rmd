---
title: "Estimates of Realized response to selection for @kulbaba-et-al"
author:
  - "Charles J. Geyer^[School of Statistics, University of Minnesota, geyer@umn.edu, https://orcid.org/0000-0003-1471-1703]"
  - "Mason W. Kulbaba^[Department of Mathematics and Science, Our Lady of the Lake University, mkulbaba@ollusa.edu, https://orcid.org/0000-0003-0619-7089]"
  - "Seema N. Sheth^[Department of Plant and Microbial Biology, North Carolina State University, ssheth3@ncsu.edu, https://orcid.org/0000-0001-8284-7608]"
  - "Rachel E. Pain^[Ecology, Evolution and Behavior Graduate Program, University of Minnesota, repain@umn.edu]"
  - "Vincent M. Eckhart^[Department of Biology, Grinnell College, eckhart@grinnell.edu]"
  - "Ruth G. Shaw^[Department of Ecology, Evolution and Behavior, University of Minnesota, shawx016@umn.edu, https://orcid.org/0000-0001-5980-9291]"
date: "August 19, 2022"
output:
  bookdown::pdf_document2:
    extra_dependencies: "amscd"
    number_sections: true
    toc: true
    toc_depth: 3
linkcolor: blue
urlcolor: blue
bibliography: foo.bib
csl: journal-of-the-royal-statistical-society.csl
link-citations: true
---

# Abstract
This work builds on the correction of @kulbaba-et-al to obtain estimates of the realized response to natural selection.

In our paper, @kulbaba-et-al,
we used aster analyses of records of components of fitness for three populations of *Chamaecrista fasciculata*, 
each grown in its home location in three years. It is not feasible to obtain every fruit before it dehisces and releases its seeds. 
For this reason and also because, in this and many other species, fruits may be numerous, it is common practice to obtain seed counts 
from a subset of fruits. Aster methodology can account for such subsampling of a fitness node, and our aster models did so. 
The error arose in the process of obtaining estimates of mean fitness and additive genetic variance for fitness. 
Specifically, the proportion of fruits sampled to obtain seed counts was correctly included in the aster models,
but the code to obtain estimates from these models did not account for the subsampling to scale up to the total number of seeds individuals produced. 
This document presents reanalyses correcting this error by implementing calculations described by @aster2, Section 8
of @tr661, and the Supplementary Material of @stanton-geddes-tiffin-shaw.
Our reanalysis shows that the error did not affect the major qualitative conclusions, though numerical values differ.
Unrelated to the matter of subsampling, we here also shift from treating "block" as a fixed factor to treating it as random. Either choice is
justifiable; particularly because of the nonlinearity of parameterizations of generalized linear models and aster models, the choice to treat blocks as
random simplifies interpretation.

# License

This work is licensed under a Creative Commons
CC0 1.0 Universal (CC0 1.0) Public Domain Dedication
(https://creativecommons.org/publicdomain/zero/1.0/).

# R

 * The version of R used to make this document is `r getRversion()`.

 * The version of the `rmarkdown` package used to make this document is
   `r packageVersion("rmarkdown")`.

 * The version of the `bookdown` package used to make this document is
   `r packageVersion("bookdown")`.

 * The version of the `aster` package used to make this document is
   `r packageVersion("aster")`.

 * The version of the `numDeriv` package used to make this document is
   `r packageVersion("numDeriv")`.

 * The version of the `kableExtra` package used to make this document is
   `r packageVersion("kableExtra")`.

As far as we know, any fairly recent version of R or these packages
will do for processing this Rmarkdown document.  We are not using
cutting edge features.

Attach packages.
```{r package}
library("aster")
library("numDeriv")
library("kableExtra")
```

# Data

The data files are
```
#gcdata.csv 
GC_3yr_seedpool.csv
#kwdata.csv
KWdat.csv
#csdata.csv
csdat.csv
```
for 

 * Grey Cloud Dunes Scientific and Natural Area

 * Kellogg-Weaver Dunes, also called McCarthy Lake, and

 * Conard Environmental Research Area (CERA),

respectively.  For more details @kulbaba-et-al.

These data files were downloaded from the GitHub repository
https://github.com/mason-kulbaba/adaptive-capacity which
contains the code and data for the analysis of the original paper.
So we are using the same data but doing a different analysis.

# Introduction

We do aster (@aster2, @reaster) analyses for an aster model with graph
$$
\begin{CD}
  1 @>\text{Ber}>> \texttt{Germ}
  @>\text{Ber}>> \texttt{flw}
  @>\text{Poi}>> \texttt{total.pods}
  @>\text{samp}>> \texttt{total.pods.collected}
  @>\text{Poi}>> \texttt{totalseeds}
\end{CD}
$$
where the variables are

 * `Germ` is germination indicator (0 = no, 1 = yes), conditionally Bernoulli.

 * `flw` is survival to flowering (0 = no, 1 = yes),
    conditionally Bernoulli.

 * `total.pods` is total number of pods produced,
   conditionally Poisson.

 * `total.pods.collected` is number of pods collected,
   conditionally Bernoulli (i.e. each pod may be collected or not).  The arrow leading to this node
   is a subsampling arrow.  The number of pods collected is
   a random sample of the pods produced.

 * `totalseeds` is total number of seeds counted from collected pods,
   conditionally Poisson.

As always with aster models, the name of the distribution for an arrow
is the name of the conditional distribution of the successor variable
given the predecessor variable.

Set graphical model description in R.
```{r graph}
vars <- c("Germ", "flw", "total.pods", "total.pods.collected", "totalseeds")
pred <- c(0, 1, 2, 3, 4)
fam <- c(1, 1, 2, 1, 2)
```

# Example Analysis

## Determine Data to Analyze

We start by doing one example, but we do it in such a way that code
can be reused for all analyses.  The following two variables determine
(entirely) the analysis to be done.
```{r mydata.myyear}
#mydata <- "gcdata.csv"
mydata <- "../KWdat.csv"
myyear <- 2015
```
We also need to specify the year of the corresponding set of offspring.

```{r myyearf}
myyearf <- 2016
```

## Read Data

Read in data.
```{r read}
dat <- read.csv(mydata)
#badname <- "G2YR2"
#rename_cohort <- with(dat, cohort == badname)
#head(rename_cohort)
#dat[rename_cohort, "cohort"] <- "field"
```

## Remove Maternal ID Zero

Parental ID Zero is "unknown" and hence should be removed
from these analyses.
```{r remove}
#zeros <- dat$paternalID == 0 | dat$maternalID == 0
zeros <- dat$maternalID == 0
dat <- dat[! zeros, ]
```

## Make Factor Variables

Show types of variables.
```{r types}
sapply(dat, class)
```
Some of these variables need to be `factor`.
```{r factor}
dat <- transform(dat,
    maternalID = as.factor(maternalID),
    paternalID = as.factor(paternalID),
    block = as.factor(block))
```

## Fix Data

Check subsampling is correct, i.e. that the number of pods sampled from a given plant is not greater than the total number of pods it was recorded to
have produced.
```{r oopsie}
oopsie <- with(dat, total.pods.collected > total.pods)
```
The following should say `FALSE`.
```{r oopsie.show}
any(oopsie)
```

For this example, there is a problem to fix.
```{r subsamp.too}
if (any(oopsie))
    dat[oopsie, ]
```

So this data error has to be corrected: we assume
`total.pods` is correct and equal to `total.pods.collected`
for these rows of the data.
```{r subsamp.fix}
if (any(oopsie))
    dat[oopsie, "total.pods.collected"] <- dat[oopsie, "total.pods"]
```

## Subset Data for pedigreed cohort

Subset the data to get one part we want to analyze separately.
Other parts are analyzed in the same way.
Divide into year-specific files.
```{r data.too}
subdat <- subset(dat, year == myyear & cohort == "greenhouse")
with(subdat, length(unique(paternalID)))
```
## Remove Paternal ID Zero

Parental ID Zero is "unknown" and hence should be removed
from these analyses.
```{r remove2}
zeros <- subdat$paternalID == 0 
subdat <- subdat[! zeros, ]
```


Show that we did the subset correctly.
```{r data.too.show}
unique(subdat$year)
```

## Subset Data for offspring cohort (field)

Subset the data to get one part we want to analyze separately.
Other parts are analyzed in the same way.
Divide into year-specific files.
```{r dataf.too}
subdatfield <- subset(dat, year == myyearf & cohort == "field")
```

Show that we did the subset correctly.
```{r dataf.too.show}
unique(subdatfield$year)
```
Drop unused levels.
```{r data.too.too}
subdat <- droplevels(subdat)
subdatfield <- droplevels(subdatfield)
```
Find grandfathers
```{r findGDs2016}
plantingdat2015 <- read.csv("KW_2015_planting_data.csv")
names(plantingdat2015)
idx <- match(subdatfield$position, plantingdat2015$position)
length(idx)
head(idx)
pos_row <- with(subdatfield, paste(position,row,sep="_"))
head(pos_row)
pos_row_planting2015 <- with(plantingdat2015, paste(position,row,sep="_"))
idx <- match(pos_row, pos_row_planting2015)
sum(is.na(idx))
matloc <- with(plantingdat2015, paste(maternalposition[idx],maternalrow[idx],sep="_"))
matlocsubdat <- with(subdat, paste(position,row,sep="_"))
idx2 <- match(matloc, matlocsubdat)
sum(is.na(idx2))
length(idx2)
nrow(subdatfield)
subdatfield <- transform(subdatfield, grandfather=subdat$paternalID[idx2])

names(subdatfield)
head(subdatfield)
with(subdatfield, length(unique(grandfather)))
```

## Reshape Data

Reshape data the way R function `aster` wants it.
```{r reshape}
redata <- reshape(subdat, varying = list(vars), direction = "long",
    timevar = "varb", times = as.factor(vars), v.names = "resp")
redataf <- reshape(subdatfield, varying = list(vars), direction = "long",
    timevar = "varb", times = as.factor(vars), v.names = "resp")
```

Add indicator variable `fit` to indicate "fitness" nodes (in these data
just one node).  Also add `root` (in these data always equal to 1).
```{r fit}
redata <- transform(redata,
    fit = as.numeric(grepl("totalseeds", as.character(varb))),
    root = 1)
redataf <- transform(redataf,
    fit = as.numeric(grepl("totalseeds", as.character(varb))),
    root = 1)
```

## Random Effect Aster Model

In our preliminary analyses of the pedigreed cohort, produced by hand-pollinations in the greenhouse, we modeled sire and dam effects separately and found their components of variance to be comparable in magnitude. This is
evidence that there are negligible contributions of dominance and maternal effects to resemblance of sibs. It is thus valid to estimate a single common
variance for the nuclear genetic contributions of sires and of dams to offspring fitness. 
In order to have the same variance for the random effects for sires and dams we do the following.
```{r random.effect}
modmat.sire <- model.matrix(~ 0 + fit:paternalID, redata)
modmat.dam <- model.matrix(~ 0 + fit:maternalID, redata)
head(colnames(modmat.sire))
head(colnames(modmat.dam))
modmat.siredam <- cbind(modmat.sire, modmat.dam)
```

```{r key.gc, echo=FALSE}
key <- tools::md5sum(mydata)
```
Then we can fit the model.
```{r random.effect.too, cache=TRUE, cache.extra=key}
rout <- reaster(resp ~ fit + varb,
    list(parental=~0 + modmat.siredam, block = ~ 0 + fit:block),
    pred, fam, varb, id, root, data = redata)
```
And show the results.
```{r random.effect.show, cache=TRUE, dependson="random.effect.too"}
summary(rout)
with(rout, length(grep("paternal", names(b))))
```

```{r debug.b}
my.b <- with(rout, b[grep("paternal", names(b))])
```

## Random Effect Aster Model for offspring generation ('field')

The offspring generation arose via open pollination of the pedigreed generation. For this reason, we do not know paternity of individuals in this generation. Eventually, we want
mean fitnesses for families descending from individual sires in the set of crosses that produced the pedigreed generation. As an initial pass, we carry out random effects analysis 
with maternal plant in the pedigreed generation as the random factor.


```{r random.effect.field, cache=TRUE}
#modmat.sire <- model.matrix(~ 0 + fit:paternalID, redata)
modmat.dam <- model.matrix(~ 0 + fit:maternalID, redataf)
modmat.grandfather <- model.matrix(~ 0 + fit:grandfather, redataf)
#head(colnames(modmat.sire))
#head(colnames(modmat.dam))
head(colnames(modmat.grandfather))
dim(modmat.grandfather)
```

```{r key.gcfield, echo=FALSE}
key <- tools::md5sum(mydata)
```
Then we can fit the model.
```{r checkerrors}
knitr::opts_chunk$set(error=TRUE)
```

```{r random.effect.field.too, cache=TRUE, cache.extra=key}
#routf.mom <- reaster(resp ~ fit + varb,
#list(parental=~0 + modmat.dam, block = ~ 0 + fit:block),
#pred, fam, varb, id, root, data = redataf)
routf.granddad <- reaster(resp ~ fit + varb,
    list(parental=~0 + modmat.grandfather, block = ~ 0 + fit:block),
    pred, fam, varb, id, root, data = redataf)
dim(modmat.grandfather)
dim(fit:block)
dim(redataf)
```

```{r debug.bf}
my.bf <- with(routf.granddad, b[grep("grandfather", names(b))])
all.equal(my.b, my.bf, check.attributes = FALSE)
```
And show the results.
```{r random.effect.field.show, cache=TRUE, dependson="random.effect.field.too"}
summary(routf.mom)
summary(routf.granddad)
bf <- routf.granddad$b
bf <- bf[grep("grandfather", names(bf))]
length(bf)
```

# Function to Map from Canonical to Mean Value Parameter

As with generalized linear models, aster models are linear on
a scale (the canonical parameter scale) that is a nonlinear transformation from the scale of biological measurement.
To complete our analysis, we convert our estimates from the canonical parameter scale
back to the measurement scale (the mean value parameter scale).
We use the map factory concept (use a function to make another function).
This provides many benefits over defining the function we want directly.
It allows us to embed information in the function we make with the factory.
It allows us to easily remake the function whenever we need it.
And the latter is important, because the map from the canonical parameter
scale to the mean value parameter scale depends on the data we have fit.
In particular, and in contrast to standard linear models, estimates of
variance components here depend on the fixed effects.
```{r factory, cache=TRUE}
map.factory <- function(rout, is.subsamp) {
    stopifnot(inherits(rout, "reaster"))
    stopifnot(is.logical(is.subsamp))
    aout <- rout$obj
    stopifnot(inherits(aout, "aster"))
    nnode <- ncol(aout$x)
    if(nnode != length(is.subsamp))
        stop("length(is.subsamp) not the number of nodes in the aster graph")
    alpha <- rout$alpha
    ifit <- which(names(alpha) == "fit")
    if (length(ifit) != 1)
        stop("no fixed effect named fit")
    # return map function
    function (b) {
        stopifnot(is.numeric(b))
        stopifnot(is.finite(b))
        stopifnot(length(b) == 1)
        alpha[ifit] <- alpha[ifit] + b
        xi <- predict(aout, newcoef = alpha,
            model.type = "conditional", is.always.parameter = TRUE)
        xi <- matrix(xi, ncol = nnode)
        # always use drop = FALSE unless you are sure you don't want that
        # here if we omit drop = FALSE and there is only one non-subsampling
        # node, the code will break (apply will give an error)
        xi <- xi[ , ! is.subsamp, drop = FALSE]
        mu <- apply(xi, 1, prod)
        # mu is unconditional mean values for model without subsampling
        # in this application all components mu are the same because no
        # covariates except varb, so just return only one
        mu[1]
    }
}
```
Here R function `map.factory` when invoked returns a function that maps
from a possible value of a parental effect on the canonical parameter scale
(what the model has) to the corresponding value on the mean value parameter
scale.  This depends on the model and the fixed effect parameters,
which are taken from argument `rout`, and it corrects for subsampling,
which is indicated by the argument `is.subsamp`.
The specific line of code that corrects for subsampling is
```
xi <- xi[ , ! is.subsamp, drop = FALSE]
```
This makes the result a function of conditional means of non-subsampling
arrows only.

Note that we are ignoring blocks.  This is the same as setting the block
effect to zero.  This is not the actual effect of any actual block. Rather, it
is something like the population mean of the population of blocks. 
Specifically, we are setting the block effect to be the mean of the
distribution that the model says block effects have (mean zero normal).
We acknowledge that the blocks are not a simple random sample
of some population of blocks, but this is not necessary for a random
effects model to be appropriate.  We are using a model with block as a
random effect merely to simplify interpretation: otherwise we would have different
estimates for each block. The use of the correction for subsampling does not
depend on the decision of whether to treat blocks as fixed or random.

**Caution:** this function does not handle the case where more than one node
of the graph contributes to `fit` nor does it check.  It assumes we have
a linear graph, which we do.
```{r check.linear}
identical(pred, seq(along = pred) - 1)
```
If we did not have a linear graph, then correction for subsampling would
be much more complicated
([appendix on that below](#appendix-mean-values-corrected-for-subsampling)).

Invoke the function to construct an R function `map` that maps from
canonical to mean value parameter values for these data.
Also vectorize this function, which is useful in certain contexts.
```{r map, cache=TRUE}
map <- map.factory(rout, vars == "total.pods.collected")

mapv <- Vectorize(map)
```

Also for the field cohort analysis: Invoke the function to construct an R function `mapf` that maps from
canonical to mean value parameter values for these data.
Also vectorize this function, which is useful in certain contexts.

```{r mapfv, cache=TRUE}
mapf <- map.factory(routf.granddad, vars == "total.pods.collected")

mapfv <- Vectorize(mapf)
```

<!--
Apparently if there are any special characters in the label, the figure
tag gets wrongly printed.  So use camelCase for labels of figure chunks.
-->
Plot this function.


```{r mapGraph,fig.align="center",fig.cap="Map from parental random effect on the canonical parameter scale to the mean value parameter scale."}
sigma.hat <- rout$sigma["parental"]
curve(mapv, from = -3 * sigma.hat, to = 3 * sigma.hat, log = "y")
```
Plot this function also for offspring cohort.
```{r mapfGraph,fig.align="center",fig.cap="Map from parental random effect on the canonical parameter scale to the mean value parameter scale."}
sigma.hat <- routf.granddad$sigma["parental"]
curve(mapfv, from = -3 * sigma.hat, to = 3 * sigma.hat, log = "y")
```

We digress to note that this map indicates a very large range of fitness
on the mean value parameter scale (Fig. \@ref(fig:mapGraph)). This may seem
surprising, but it results from the nonlinearity of the relationship between
the canonical parameter scale and the mean value parameter scale and 
follows the conventional logic of generalized linear mixed models (GLMM)
[@stiratelli-laird-ware] or aster models with random effects [@reaster].
Admittedly, three standard deviations is a fairly extreme value for a normal
random variable (happens with probability `r 2 * pnorm(-3)`).  Similar issues affect
all GLMM and aster models with random effects.

# Breeding Value Estimates

R function `reaster` provides estimates of the "breeding values"
(in scare quotes) on the
canonical parameter scale.  Of course, these are not precisely estimates,
because breeding values are random effects rather than unknown parameters.
So they are more analogous to BLUPS (best linear unbiased predictors) of breeding values in conventional
quantitative genetics.  Except they are not really that either due to the
nonlinearity of the mapping from canonical to mean values shown above.
If we replace BLUP by best median unbiased, then maybe we have some sort
of analogy (because medians map to medians going through any monotone
transformation).

Regardless, we map these quantities to the mean value parameter scale.
We do this just for breeding values of sires (in 'greenhouse' cohort). 
These are same individuals called 'grandfathers' in the 'field' cohort. We also obtain the 
random effect estimates for them, based on the field cohort.
```{r sire.breeding}
b <- rout$b
head(names(b))
idx <- grep("paternal", names(b))
b <- b[idx]
length(b)
```

```{r grandsire.effects}
bf <- routf.granddad$b
head(names(bf))
idx <- grep("grandfather", names(bf))
bf <- bf[idx]

length(bf)
```

Fix up names so not so verbose.
```{r fixnames}
names(b) <- sub("modmat.siredamfit:", "", names(b))
```
```{r fixnamesf}
names(bf) <- sub("modmat.grandfather:", "", names(bf))
```

```{r debug}
all.equal(b, bf, check.attributes = FALSE)
all.equal(my.b, b, check.attributes = FALSE)
all.equal(my.bf, bf, check.attributes = FALSE)
```

# Obtain realized genetically based change in mean fitness within parental generation
We now compute the expressions in mf2 to partition the change in mean fitness between generations
into components of interest. There are 5 bulleted expressions. The first is the genetic change in
mean fitness of the parental ('greenhouse') generation in the envt in which selection took place.

```{r genprevdeltaW, cache=TRUE}
mu <- mapv(b)

popmeanbefore <- mean(mu)

popmeanbefore

q <- mu/sum(mu)

sum(q*mu)
freqchange <- q - 1/length(b)

fammeanchange <- freqchange * mu

genprevWchange <- sum(fammeanchange)
genprevWchange

```

```{r deltaWtotal, cache=TRUE}
muf <- mapfv(bf)
offspringmeanW <- sum(q*muf)
offspringmeanW 

totalWchange <- sum(q*muf) - popmeanbefore
totalWchange
```

# Fit Models for the other cohorts of the Same set of crosses

The first thing we need to do is save our model fit so we do not clobber
it with a new model fit.  First make an empty list.
```{r fit.save.zero, cache=TRUE}
save.rout <- list()
save.pedigreedmean <- list()
save.routf <- list()
save.offspring <- list()
```
Then save the fit we have.
```{r fit.save.one, cache=TRUE, dependson="random.effect.too"}
site.name <- substr(mydata, 1, 2)
fit.name <- paste0(site.name, myyear)
fit.name
save.rout[[fit.name]] <- rout
save.pedigreedmean[[fit.name]] <- popmeanbefore
```

Also for offspring
```{r offspringmeanW.save, cache=TRUE, dependson="random.effect.field.too"}
site.name <- substr(mydata, 1, 2)
fit.name <- paste0(site.name, myyearf)
fit.name
save.routf[[fit.name]] <- routf.granddad
save.offspring[[fit.name]] <- offspringmeanW
```

Now we need to put stuff done above in a loop.  In the chunk below, we reuse
multiple code chunks above (this is not visible in the PDF output, you must
look at the Rmd source file).
```{r fit.some.more, cache=TRUE, cache.extra=key, error=TRUE}
for (myyear in 2016:2017) {
<<data.too>>
<<data.too.too>>
<<reshape>>
<<fit>>
<<random.effect>>
<<random.effect.too>>
<<factory>>
<<map>>
<<sire.breeding>>
<<genprevdeltaW>>
<<fit.save.one>>
print(popmeanbefore)
print(genprevWchange)
}
```

Also must do the computations for the second offspring generation (named G2YR3 in thedataset, grown in 2017). 
Unfortunately, the dataset is structured a bit differently, 
and the code below addresses this.

```{r fit.2ndoffspring.cohort, cache=TRUE, cache.extra=key,error=TRUE}
myyearf <- 2017
<<dataf.too>>
subdatfield$grandfather <- subdatfield$paternalID
<<data.too.too>>
<<reshape>>
<<fit>>
<<random.effect.field>>
<<random.effect.field.too>>
<<factory>>
<<mapf>>
<<mapfv>>
<<grandsire.effects>>
<<deltaWtotal>>
<<offspringmeanW.save>>
print(offspringmeanW)
```

What have we got?
```{r show.save.rout}
names(save.rout)


names(save.rout$GC2015)
names(save.rout$GC2016)
names(save.rout$GC2017)

print(save.pedigreedmean$GC2015)
print(save.pedigreedmean$GC2016)
print(save.pedigreedmean$GC2017)

print(save.offspring$GC2016)
print(save.offspring$GC2017)
```

Obtain the change in mean fitness due solely to different environments in the two years.
last bullet point in mf2 (p.3).
