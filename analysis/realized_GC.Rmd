---
title: "Estimates of Realized Response to Selection for @kulbaba-et-al"
author:
  - "Charles J. Geyer^[School of Statistics, University of Minnesota, geyer@umn.edu, https://orcid.org/0000-0003-1471-1703]"
  - "Mason W. Kulbaba^[Department of Mathematics and Science, Our Lady of the Lake University, mkulbaba@ollusa.edu, https://orcid.org/0000-0003-0619-7089]"
  - "Seema N. Sheth^[Department of Plant and Microbial Biology, North Carolina State University, ssheth3@ncsu.edu, https://orcid.org/0000-0001-8284-7608]"
  - "Rachel E. Pain^[Ecology, Evolution and Behavior Graduate Program, University of Minnesota, repain@umn.edu]"
  - "Vincent M. Eckhart^[Department of Biology, Grinnell College, eckhart@grinnell.edu]"
  - "Ruth G. Shaw^[Department of Ecology, Evolution and Behavior, University of Minnesota, shawx016@umn.edu, https://orcid.org/0000-0001-5980-9291]"
date: "August 19, 2022"
output:
  bookdown::pdf_document2:
    extra_dependencies: "amscd"
    number_sections: true
    toc: true
    toc_depth: 3
linkcolor: blue
urlcolor: blue
bibliography: foo.bib
csl: journal-of-the-royal-statistical-society.csl
link-citations: true
---

# Abstract

This work builds on @kulbaba-et-al and the correction to it [@zenodo]
to obtain estimates of the realized response to natural selection.
Those articles
presented estimates of mean fitness and additive genetic variance for fitness
for three populations of *Chamaecrista fasciculata*,
each grown in its home location in three years via aster analyses of records of components of fitness for a pedigreed set of individuals.
Here, we consider the realized change in mean fitness from one generation to the next, for comparison with the prediction from Fisher's
Fundamental Theorem of Natural Selection (FFTNS).
In @mean-fitness change in mean fitness in one generation is divided
into three parts:
that due to change in genetic composition described by FFTNS,
that due to change in genetic composition not described by FFTNS, and
that due to change in environment.
Here, we obtain estimates of a) mean fitness of the pedigreed parental populations before selection (previously presented in @kulbaba-et-al and its
correction); b) mean fitness of the pedigreed parental population after selection (i.e. accounting for the change in representation of the families
reflected in differential seed production); and mean fitness of the offspring of the pedigreed sets
(i.e. the outcome of natural selection on the parental
generation when grown in the same sites in the following year).

We also obtain standard errors of our estimates.

# License

This work is licensed under a Creative Commons
CC0 1.0 Universal (CC0 1.0) Public Domain Dedication
(https://creativecommons.org/publicdomain/zero/1.0/).

# R

 * The version of R used to make this document is `r getRversion()`.

 * The version of the `rmarkdown` package used to make this document is
   `r packageVersion("rmarkdown")`.

 * The version of the `bookdown` package used to make this document is
   `r packageVersion("bookdown")`.

 * The version of the `aster` package used to make this document is
   `r packageVersion("aster")`.

 * The version of the `numDeriv` package used to make this document is
   `r packageVersion("numDeriv")`.

 * The version of the `digest` package used to make this document is
   `r packageVersion("digest")`.

 * The version of the `Matrix` package used to make this document is
   `r packageVersion("Matrix")`.

Attach packages.
```{r package}
library("aster")
library("numDeriv")
library("digest")
library("Matrix")
```

Need at least version 1.2-1 of R package `aster` for R generic function `vcov`
to work on results of calls to R functions `aster` and `reaster`.
```{r aster-version}
stopifnot(compareVersion(as.character(packageVersion("aster")), "1.2-1") >= 0)
```

```{r checkerrors, echo=FALSE}
# make all code chunks after this one have option error=TRUE
# knitr::opts_chunk$set(error=TRUE)
```

# Data

For the analyses here. the data files are
```
GCdat.csv
KWdat.csv
csdat.csv
```
for 

 * Grey Cloud Dunes Scientific and Natural Area

 * Kellogg-Weaver Dunes, also called McCarthy Lake, and

 * Conard Environmental Research Area (CERA),

respectively.  These files include the same data on the same individuals
as in the data files used by @kulbaba-et-al and @zenodo but also include
more individuals, who are offspring of those analyzed before.
For more details, see @kulbaba-et-al.

For this document the data file is
```
GCdat.csv
```

# Introduction

We do aster (@aster2, @reaster) analyses for an aster model with graph
$$
\begin{CD}
  1 @>\text{Ber}>> \texttt{Germ}
  @>\text{Ber}>> \texttt{flw}
  @>\text{Poi}>> \texttt{total.pods}
  @>\text{samp}>> \texttt{total.pods.collected}
  @>\text{Poi}>> \texttt{totalseeds}
\end{CD}
$$
where the variables are

 * `Germ` is germination indicator (0 = no, 1 = yes), conditionally Bernoulli.

 * `flw` is survival to flowering (0 = no, 1 = yes),
    conditionally Bernoulli.

 * `total.pods` is total number of pods produced,
   conditionally Poisson.

 * `total.pods.collected` is number of pods collected,
   conditionally Bernoulli (i.e. each pod may be collected or not).  The arrow leading to this node
   is a subsampling arrow.  The number of pods collected is
   a random sample of the pods produced.

 * `totalseeds` is total number of seeds counted from collected pods,
   conditionally Poisson.

As always with aster models, the name of the distribution for an arrow
is the name of the conditional distribution of the successor variable
given the predecessor variable.

Set graphical model description in R.
```{r graph}
vars <- c("Germ", "flw", "total.pods", "total.pods.collected", "totalseeds")
pred <- c(0, 1, 2, 3, 4)
fam <- c(1, 1, 2, 1, 2)
```

# Example Analysis

## Determine Data to Analyze

We start by doing one example, but we do it in such a way that code
can be reused for all analyses.  The following two variables determine
(entirely) the analysis to be done.
```{r mydata.myyear}
mydata <- "GCdat.csv"
myyear <- 2015
```
We also need to specify the year of the corresponding set of offspring.

```{r myyearf}
myyearf <- myyear + 1
```

## Read Data

Read in data.
```{r read}
dat <- read.csv(mydata)
```

## Remove Maternal ID Zero

Parental ID Zero is "unknown" and hence should be removed
from these analyses.
```{r remove}
dat <- subset(dat, maternalID != 0)
```

## Make Factor Variables

Show types of variables.
```{r types}
sapply(dat, class)
```
Some of these variables need to be `factor`.
```{r factor}
dat <- transform(dat,
    maternalID = as.factor(maternalID),
    paternalID = as.factor(paternalID),
    block = as.factor(block))
```

## Fix Data

Check subsampling is correct, i.e. that the number of pods sampled from a given plant is not greater than the total number of pods it was recorded to
have produced.
```{r oopsie}
oopsie <- with(dat, total.pods.collected > total.pods)
```
The following should say `FALSE`.
```{r oopsie.show}
any(oopsie)
```

For this example, there is a problem to fix.
```{r subsamp.too}
if (any(oopsie))
    dat[oopsie, ]
```

So this data error has to be corrected: we assume
`total.pods` is correct and equal to `total.pods.collected`
for these rows of the data.
```{r subsamp.fix}
if (any(oopsie))
    dat[oopsie, "total.pods.collected"] <- dat[oopsie, "total.pods"]
```

## Subset Data for Pedigreed Cohort

Subset the data to get one part we want to analyze separately.
```{r data.too}
subdat <- subset(dat, year == myyear & cohort == "greenhouse")
with(subdat, length(unique(paternalID)))
```

And another part we want to analyze in the same way.
```{r data.too.next}
subdatnext <- subset(dat, year == myyearf & cohort == "greenhouse")
with(subdatnext, length(unique(paternalID)))
```

## Remove Paternal ID Zero

Parental ID Zero is "unknown" and hence should be removed
from these analyses.
```{r remove2}
subdat <- subset(subdat, paternalID != 0)
subdatnext <- subset(subdatnext, paternalID != 0)
```


Show that we did the subset correctly.
```{r data.too.show}
unique(subdat$year)
unique(subdatnext$year)
```

## Subset Data for offspring cohort (field)

Now for offspring data.
Subset the data to get one part we want to analyze separately.
Other parts are analyzed in the same way.
Divide into year-specific data frames.
```{r dataf.too}
subdatfield <- subset(dat, year == myyearf & cohort == "field")
```

Show that we did the subset correctly.
```{r dataf.too.show}
unique(subdatfield$year)
```
Drop unused levels.
```{r data.too.too}
subdat <- droplevels(subdat)
subdatnext <- droplevels(subdatnext)
subdatfield <- droplevels(subdatfield)
```

## Find Grandfathers

Now we have to look up grandfathers of the offspring generation.
For these offspring, the `paternalID` is zero (meaning unknown)
and the `maternalID` is the `positionID` of the maternal plant.
So the grandfather is the `paternalID` of this maternal plant.
```{r findGDs2016}
idx <- match(subdatfield$maternalID, subdat$positionID)
subdatfield <- transform(subdatfield, grandfather=subdat$paternalID[idx])
names(subdatfield)
head(subdatfield)
with(subdatfield, length(unique(maternalID)))
with(subdatfield, length(unique(grandfather)))
with(subdatfield, unique(grandfather))
```

## Reshape Data

Reshape data the way R function `aster` wants it.
```{r reshape}
redata <- reshape(subdat, varying = list(vars), direction = "long",
    timevar = "varb", times = as.factor(vars), v.names = "resp")
redataf <- reshape(subdatfield, varying = list(vars), direction = "long",
    timevar = "varb", times = as.factor(vars), v.names = "resp")
redatanext <- reshape(subdatnext, varying = list(vars), direction = "long",
    timevar = "varb", times = as.factor(vars), v.names = "resp")
```

Add indicator variable `fit` to indicate "fitness" nodes (in these data
just one node).  Also add `root` (in these data always equal to 1).
```{r fit}
redata <- transform(redata,
    fit = as.numeric(grepl("totalseeds", as.character(varb))),
    root = 1)
redataf <- transform(redataf,
    fit = as.numeric(grepl("totalseeds", as.character(varb))),
    root = 1)
redatanext <- transform(redatanext,
    fit = as.numeric(grepl("totalseeds", as.character(varb))),
    root = 1)
```

## Random Effect Aster Model

In our preliminary analyses of the pedigreed cohort, produced by hand-pollinations in the greenhouse, we modeled sire and dam effects separately and found their components of variance to be comparable in magnitude. This is
evidence that there are negligible contributions of dominance and maternal effects to resemblance of sibs. It is thus valid to estimate a single common
variance for the nuclear genetic contributions of sires and of dams to offspring fitness. 
In order to have the same variance for the random effects for sires and dams we do the following.
```{r random.effect}
modmat.sire <- model.matrix(~ 0 + fit:paternalID, redata)
modmat.dam <- model.matrix(~ 0 + fit:maternalID, redata)
head(colnames(modmat.sire))
head(colnames(modmat.dam))
modmat.siredam <- cbind(modmat.sire, modmat.dam)
```

```{r key.gc, echo=FALSE}
key <- tools::md5sum(mydata)
key.prev <- digest(redata)
key.par <- digest(redatanext)
key.off <- digest(redataf)
```

Then we can fit the model.
```{r random.effect.too, cache=TRUE, cache.extra=c(key,key.prev)}
rout <- reaster(resp ~ fit + varb,
    list(parental=~0 + modmat.siredam, block = ~ 0 + fit:block),
    pred, fam, varb, id, root, data = redata)
```
And show the results.
```{r random.effect.show, cache=TRUE, dependson="random.effect.too"}
summary(rout, standard.deviation = FALSE)
```

Look at the first step towards standard errors.
```{r random.effect.vcov, cache=TRUE, dependson="random.effect.too"}
vout <- vcov(rout, re.too = TRUE, standard.deviation = FALSE)
```

## Another Random Effect Aster Model

```{r random.effect.next.modmat}
modmat.sire.next <- model.matrix(~ 0 + fit:paternalID, redatanext)
modmat.dam.next <- model.matrix(~ 0 + fit:maternalID, redatanext)
modmat.siredam.next <- cbind(modmat.sire.next, modmat.dam.next)
```

```{r random.effect.next, cache=TRUE, cache.extra=c(key,key.par)}
rout.next <- reaster(resp ~ fit + varb,
    list(parental=~0 + modmat.siredam.next, block = ~ 0 + fit:block),
    pred, fam, varb, id, root, data = redatanext)
```
And show the results.
```{r random.effect.show.next, cache=TRUE, dependson="random.effect.next"}
summary(rout.next, standard.deviation = FALSE)
```
Also calculate variance-covariance matrix of estimates.
```{r random.effect.vcov.next, cache=TRUE, dependson="random.effect.next"}
vout.next <- vcov(rout.next, re.too = TRUE, standard.deviation = FALSE)
```

## Random Effect Aster Model for offspring generation ('field')

### Grandfather Effects

The offspring generation arose via open pollination of the pedigreed generation. 
For this reason, we do not know paternity of individuals in this generation.
We focus on
mean fitnesses for families descending from individual sires in the set
of crosses that produced the pedigreed generation.
```{r random.effect.grandfather, cache=TRUE, cache.extra=c(key,key.off)}
routf.granddad <- reaster(resp ~ fit + varb,
    list(parental = ~ 0 + fit:grandfather, block = ~ 0 + fit:block),
    pred, fam, varb, id, root, data = redataf)
```
```{r random.effect.grandfather.summary, cache=TRUE, dependson="random.effect.grandfather"}
summary(routf.granddad, standard.deviation = FALSE)
```

Also calculate variance-covariance matrix of estimates.
```{r random.effect.vcov.grandfather, cache=TRUE, dependson="random.effect.grandfather"}
vout.granddad <- vcov(routf.granddad, re.too = TRUE, standard.deviation = FALSE)
```

### Maternal Effects

For interest's sake, we also carry out random effects analysis 
with maternal plant in the pedigreed generation as the random factor.
We do not use this analysis in further analysis.  (Rather, we use
the preceding one with grandsire effects.)
```{r random.effect.dam, cache=TRUE, cache.extra=key}
routf.mom <- reaster(resp ~ fit + varb,
    list(parental = ~ 0 + fit:maternalID, block = ~ 0 + fit:block),
    pred, fam, varb, id, root, data = redataf)
```
```{r random.effect.dam.summary}
summary(routf.mom)
```

# Mapping Sire and Grandsire Effects to Mean Values

We follow Section 9 of @zenodo *mutatis mutandis*.  The main changes are
here we will have a vectorizing function that simultaneously does
mean fitness values for a specified set of individuals.
```{r map}
map.factory <- function(rout, is.subsamp, include.random, which.ind) {
    stopifnot(inherits(rout, "reaster"))
    stopifnot(is.logical(is.subsamp))
    stopifnot(is.logical(include.random))
    stopifnot(is.logical(which.ind))
    aout <- rout$obj
    stopifnot(inherits(aout, "aster"))
    nnode <- ncol(aout$x)
    nind <- nrow(aout$x)
    if (nnode != length(is.subsamp))
        stop("length(is.subsamp) not the number of nodes in the aster graph")
    if (nind != length(which.ind))
        stop("length(which.ind) not the number of individual aster data")
    fixed <- rout$fixed
    random <- rout$random
    alpha <- rout$alpha
    bee <- rout$b
    if(length(bee) != length(include.random))
        stop("length(include.random) not the number of random effects",
            " in the aster model")
    # fake object of class aster
    fake.out <- aout
    fake.beta <- c(alpha, bee[include.random])
    modmat.random <- Reduce(cbind, random)
    stopifnot(ncol(modmat.random) == length(bee))
    modmat.random <- modmat.random[ , include.random, drop = FALSE] 
    fake.modmat <- cbind(fixed, modmat.random)
    # now have to deal with objects of class aster (as opposed to reaster)
    # think model matrices are three-way arrays.
    stopifnot(prod(dim(aout$modmat)[1:2]) == nrow(fake.modmat))
    fake.modmat <- array(as.vector(fake.modmat),
        dim = c(dim(aout$modmat)[1:2], ncol(fake.modmat)))
    fake.out$modmat <- fake.modmat
    nparm <- length(rout$alpha) + length(rout$b) + length(rout$nu)
    is.alpha <- seq(1, nparm) %in% seq_along(rout$alpha)
    is.bee <- seq(1, nparm) %in% (length(rout$alpha) + seq_along(rout$b))
    function(alphabeenu) {
        if (! missing(alphabeenu)) {
            stopifnot(is.numeric(alphabeenu))
            stopifnot(is.finite(alphabeenu))
            delta.alpha <- alphabeenu[is.alpha]
            delta.bee <- alphabeenu[is.bee]
            fake.beta <- fake.beta + c(delta.alpha, delta.bee[include.random])
        }
        fake.out$coefficients <- fake.beta
        pout <- predict(fake.out, model.type = "conditional",
            is.always.parameter = TRUE)
        xi <- matrix(pout, ncol = nnode)
        xi <- xi[ , ! is.subsamp, drop = FALSE]
        mu <- apply(xi, 1, prod)
        return(mu[which.ind])
    }
}
```

Test.  Calculate for first `reaster` fit.
```{r map.prev}
idx <- match(levels(subdat$paternalID), subdat$paternalID)
which.ind <- rep(FALSE, nrow(subdat))
which.ind[idx] <- TRUE
setequal(subdat$paternalID[which.ind], levels(subdat$paternalID))

doit.prev <- map.factory(rout, grepl("collected", vars),
    grepl("paternal", names(rout$b)), which.ind)
mu.prev <- doit.prev()
```

We need a help page (not a literal one) for R function `map.factory`,
so here goes.

R function `map.factory` produces a function with one argument
that calculates mean fitness estimates for individuals
(not for the population) from a `reaster` fit.
That is, it is a function whose value is another function.
The arguments of `map.factory` are

 * `rout` an object returned by R function `reaster`,

 * `is.subsamp` a logical vector that indicates which nodes of the
   aster graph for a single individual are subsampling nodes,

 * `include.random` a logical vector that indicates which random effects
   of the reaster fit we want to use in the estimation (in this document
   sire or grandsire effects, as the case may be),

 * `which.ind` a logical vector that indicates which individuals in the
   data for the reaster fit we want to use for estimation (when we only
   use sire effects for prediction all individuals with the same sire
   have the same prediction because we have no fixed effects that differ
   among individuals).

The value of this function is another function with signature
```
function(alphabeenu)
```

The argument may be missing, in which case it is taken to be the zero vector.
Otherwise, it is the length of the entire parameter vector
```
length(rout$alpha) + length(rout$b) + length(rout$nu)
```
even though not all of these are used in the prediction.
(This is convenient for evaluating gradients numerically.)  The argument
`alphabeenu` is not the parameter vector but rather the delta from the MLE
(so when missing or zero, we are evaluating the MLE prediction).

**Warning:** This function only works for linear aster graphs, as explained
in Section 9 of @zenodo.  Appendix (Section 16) of @zenodo says how to
correct the `map` function of that paper for a non-linear graph.
Similar considerations would apply here.

Now redo for the other `reaster` objects.

```{r map.par}
setequal(levels(subdat$paternalID), levels(subdatnext$paternalID))
idx <- match(levels(subdat$paternalID), subdatnext$paternalID)
which.ind <- rep(FALSE, nrow(subdatnext))
which.ind[idx] <- TRUE
setequal(subdatnext$paternalID[which.ind], levels(subdat$paternalID))

doit.par <- map.factory(rout.next, grepl("collected", vars),
    grepl("paternal", names(rout.next$b)), which.ind)
mu.par <- doit.par()
```

```{r map.off.preamble}
setequal(subdat$paternalID, subdatfield$grandfather)
```
Not all sires are grandsires, so we vary the above.
```{r map.off}
idx <- match(sort(unique(subdatfield$grandfather)), subdatfield$grandfather)
which.ind <- rep(FALSE, nrow(subdatfield))
which.ind[idx] <- TRUE
setequal(subdatfield$grandfather[which.ind],
    sort(unique(subdatfield$grandfather)))

doit.off <- map.factory(routf.granddad, grepl("collected", vars),
    grepl("paternal", names(routf.granddad$b)), which.ind)
mu.off <- doit.off()
```

# Decomposition of Difference in Mean Fitness

We now follow @mean-fitness.  The total change in mean fitness from
one generation to the next is given by equation (1) in that document.

Before we can do that, we need to account for not all sires being grandsires.
```{r check.and.match}
identical(sort(unique(subdat$paternalID)),
    sort(unique(subdatnext$paternalID)))
identical(sort(unique(subdat$paternalID)),
    sort(unique(subdatfield$grandfather)))
all(is.element(sort(unique(subdatfield$grandfather)),
    sort(unique(subdat$paternalID))))
idx <- match(sort(unique(subdatfield$grandfather)), levels(subdat$paternalID))
```

Now we implement equation (1) of @mean-fitness.
```{r total.change}
delta.total <- sum(mu.off * mu.prev[idx]) / sum(mu.prev[idx]) -  mean(mu.prev)
delta.total
```

Now we implement equation (2a) of @mean-fitness.
```{r environmental.change}
delta.environ <- mean(mu.par - mu.prev)
delta.environ
```

Now we implement equation (2b) of @mean-fitness.
```{r fftns.change}
delta.fftns <- sum((mu.prev / sum(mu.prev) - 1 / length(mu.prev)) * mu.par)
delta.fftns
```

Now we implement equation (2c) of @mean-fitness.
```{r non.fftns.change}
delta.non.fftns <- delta.total - delta.environ - delta.fftns
delta.non.fftns
```

```{r delta-table, echo=FALSE, tab.cap="Change in Mean Fitness in One Generation"}
# note cannot have any dots in chunk label because it screws up caption
# that is, delta.table is fubar but delta-table is OK
foo <- c(delta.fftns, delta.non.fftns, delta.environ, delta.total)
names(foo) <- c("FFTNS", "non-FFTNS", "environmental", "total")
foo <- cbind(foo)
colnames(foo) <- "Estimate"
knitr::kable(foo, digits=4)
```
Table \@ref(tab:delta-table) shows these in a nice table.

# Standard Errors for These Estimates

Because we did the estimates in two steps, we do the standard errors in
two steps likewise.

## Standard Errors for Individual Mean Fitnesses

Calculate variance-covariance matrix for estimated individual mean fitnesses
in one subset.
```{r vcov-prev-jacobian,cache=TRUE,dependson="random.effect.too"}
zero <- rep(0, length(rout$alpha) + length(rout$b) + length(rout$nu))
jack.prev <- jacobian(doit.prev, zero)
```

Now apply the delta method to obtain variance-covariance matrix for `mu.prev`
```{r vcov-prev, cache=TRUE, dependson=c("vcov-prev-jacobian","random.effect.vcov")}
vcov.mu.prev <- jack.prev %*% vout %*% t(jack.prev)
length(mu.prev)
dim(vcov.mu.prev)
```

Looks good.  Now do the others.
```{r vcov-par, cache=TRUE, dependson=c("random.effect.next","random.effect.vcov.next")}
jack.par <- jacobian(doit.par, zero)
vcov.mu.par <- jack.par %*% vout.next %*% t(jack.par)
```
```{r vcov-off, cache=TRUE, dependson=c("random.effect.grandfather","random.effect.vcov.grandfather")}
zero <- rep(0, length(routf.granddad$alpha) + length(routf.granddad$b) +
    length(routf.granddad$nu))
jack.off <- jacobian(doit.off, zero)
vcov.mu.off <- jack.off %*% vout.granddad %*% t(jack.off)
```

## Standard Errors for Changes in Population Mean Fitness and Its Parts

We start by making a joint variance-covariance matrix for all the individual
estimates.  Since these estimate vectors are for different experiments, hence
statistically independent, this matrix is block diagonal.
```{r block}
vcov.combo <- bdiag(vcov.mu.prev, vcov.mu.par, vcov.mu.off)
```

Now we need a function that calculates our population mean fitness estimates
from the combined individual mean fitness vector.
```{r combo}
mu.combo <- c(mu.prev, mu.par, mu.off)
is.prev <- seq_along(mu.combo) %in% seq_along(mu.prev)
is.par <- seq_along(mu.combo) %in% (length(mu.prev) + seq_along(mu.par))
is.off <- seq_along(mu.combo) %in% (length(mu.prev) + length(mu.par) +
    seq_along(mu.par))
all.equal(mu.prev, mu.combo[is.prev])
all.equal(mu.par, mu.combo[is.par])
all.equal(mu.off, mu.combo[is.off])
doit.combo <- function(moo) {
    stopifnot(is.numeric(moo))
    stopifnot(is.finite(moo))
    stopifnot(length(moo) == length(mu.combo))
    mu.prev <- moo[is.prev]
    mu.par <- moo[is.par]
    mu.off <- moo[is.off]
    idx <- match(sort(unique(subdatfield$grandfather)),
        levels(subdat$paternalID))
    delta.total <- sum(mu.off * mu.prev[idx]) / sum(mu.prev[idx]) - mean(mu.prev)
    delta.environ <- mean(mu.par - mu.prev)
    delta.fftns <- sum((mu.prev / sum(mu.prev) - 1 / length(mu.prev)) * mu.par)
    delta.non.fftns <- delta.total - delta.environ - delta.fftns
    result <- c(delta.fftns, delta.non.fftns, delta.environ, delta.total)
    names(result) <- c("FFTNS", "non.FFTNS", "environmental", "total")
    return(result)
}
```

Try it.
```{r test.combo}
deltas <- doit.combo(mu.combo)
identical(c(delta.fftns, delta.non.fftns, delta.environ, delta.total),
    as.vector(deltas))
```

Good!  So now calculate Jacobian for this part of the change-of-parameter.
```{r jack.combo,cache=TRUE,dependson=c("vcov-prev","vcov-par","vcov-off")}
jack.combo <- jacobian(doit.combo, mu.combo)
vcov.deltas <- jack.combo %*% vcov.combo %*% t(jack.combo)
```

Make a nice table.
```{r table}
foo <- cbind(deltas, sqrt(diag(vcov.deltas)))
colnames(foo) <- c("Estimate", "Std. Error")
foo
```
```{r delta-table-with-se, echo=FALSE, tab.cap="Change in Mean Fitness in One Generation"}
# note cannot have any dots in chunk label because it screws up caption
# that is, delta.table is fubar but delta-table is OK
rownames(foo)[2] <- "non-FFTNS genetic"
knitr::kable(foo, digits=4)
```
Table \@ref(tab:delta-table-with-se) shows these in a nice table.


# References

