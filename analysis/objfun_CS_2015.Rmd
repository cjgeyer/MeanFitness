---
title: "New Objective Function for Reaster Problem"
author: "Charles J. Geyer"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  bookdown::pdf_document2:
    extra_dependencies: "amscd"
    number_sections: true
    toc: true
    toc_depth: 3
linkcolor: blue
urlcolor: blue
bibliography: foo.bib
csl: journal-of-the-royal-statistical-society.csl
link-citations: true
---

# License

This work is licensed under a Creative Commons
CC0 1.0 Universal (CC0 1.0) Public Domain Dedication
(https://creativecommons.org/publicdomain/zero/1.0/).

The R markdown source for this document is the file `realized.Rmd`
in the GitHub private repository https://github.com/cjgeyer/mf
which will be made public whenever a paper based on it is submitted.

# R

 * The version of R used to make this document is `r getRversion()`.

 * The version of the `rmarkdown` package used to make this document is
   `r packageVersion("rmarkdown")`.

 * The version of the `bookdown` package used to make this document is
   `r packageVersion("bookdown")`.

 * The version of the `aster` package used to make this document is
   `r packageVersion("aster")`.

 * The version of the `numDeriv` package used to make this document is
   `r packageVersion("numDeriv")`.

 * The version of the `Matrix` package used to make this document is
   `r packageVersion("Matrix")`.

 * The version of the `minqa` package used to make this document is
   `r packageVersion("minqa")`.

Attach packages.
```{r package}
library("aster")
library("numDeriv")
library("Matrix")
library("minqa")
```

Need at least version 1.3.0 of R package `aster` for
R function `objfun.factory` that makes objective function for aster models
with random effects (Laplace approximation to actual log likelihood)
equation (7) of @reaster except that R function `objfun.factory` no longer
uses the ``second approximation'' that treats $\widehat{W}$ in that equation
as a constant matrix.  Hence we should rewrite it as
\begin{equation}
\begin{split}
   p(\alpha, b, \nu)
   & =
   - l(a + M \alpha + Z b)
   + \tfrac{1}{2} b^T D^{-1} b
   \\
   & \quad
   + \tfrac{1}{2} \log
   \det\bigl[ Z^T W(a + M \alpha + Z b) Z D + I \bigr]
\end{split}
\end{equation}

```{r aster-version}
stopifnot(compareVersion(as.character(packageVersion("aster")), "1.3") >= 0)
```

```{r checkerrors, echo=FALSE}
# make all code chunks after this one have option error=TRUE
# knitr::opts_chunk$set(error=TRUE)
```

# Data

For the analyses here. the data files are
```{r data.input}
load("mf.rda")
ls()
sapply(data.primary, class)
```
for 

 * Conard Environmental Research Area (CERA),

 * Grey Cloud Dunes Scientific and Natural Area, and

 * Kellogg-Weaver Dunes, also called McCarthy Lake,

respectively.  These files include the same data on the same individuals
as in the data files used by @kulbaba-et-al and @zenodo but also include
more individuals, who are offspring of those analyzed before.
For more details, see @kulbaba-et-al.

Much preprocessing of these data has already been done.  See
the file `fixup-data.pdf` in this repository.

# Introduction

We do aster (@aster2, @reaster) analyses for an aster model with graph
$$
\begin{CD}
  1 @>\text{Ber}>> \texttt{Germ}
  @>\text{Ber}>> \texttt{flw}
  @>\text{Poi}>> \texttt{total.pods}
  @>\text{samp}>> \texttt{total.pods.collected}
  @>\text{Poi}>> \texttt{totalseeds}
\end{CD}
$$
where the variables are

 * `Germ` is germination indicator (0 = no, 1 = yes), conditionally Bernoulli.

 * `flw` is survival to flowering (0 = no, 1 = yes),
    conditionally Bernoulli.

 * `total.pods` is total number of pods produced,
   conditionally Poisson.

 * `total.pods.collected` is number of pods collected,
   conditionally Bernoulli (i.e. each pod may be collected or not).
   The arrow leading to this node
   is a subsampling arrow.  The number of pods collected is
   a random sample of the pods produced.

 * `totalseeds` is total number of seeds counted from collected pods,
   conditionally Poisson.

As always with aster models, the name of the distribution for an arrow
is the name of the conditional distribution of the successor variable
given the predecessor variable.
The arrow labeled `samp` is a subsampling arrow.  It is a Bernoulli
arrow but the sampling is experimental rather than biological.

Set graphical model description in R.
```{r graph}
vars <- c("Germ", "flw", "total.pods", "total.pods.collected", "totalseeds")
pred <- c(0, 1, 2, 3, 4)
fam <- c(1, 1, 2, 1, 2)
```

```{r key.gc, echo=FALSE}
key.data <- tools::md5sum("mf.rda")
```

# Analysis with R Function Reaster

To save time we just do reaster for one site-year combination.
Below we extract site and year from the filename of this document.
```{r site-year, cache=TRUE}
foo <- commandArgs()
foo <- rev(foo)[1]
foo <- strsplit(foo, "[_.]")
foo <- foo[[1]]
site <- foo[2]
year <- foo[3]
site
year
```

## With R Function Reaster

```{r reaster.parents, cache=TRUE, cache.extra=key.data, depends="site-year"}
subdat <- subset(data.primary[[site]], year == year & cohort == "greenhouse")
subdat <- droplevels(subdat)
redata <- reshape(subdat, varying = list(vars), direction = "long",
    timevar = "varb", times = as.factor(vars), v.names = "resp")
redata <- transform(redata,
    fit = as.numeric(grepl("totalseeds", as.character(varb))),
    root = 1)
modmat.sire <- model.matrix(~ 0 + fit:paternalID, redata)
modmat.dam <- model.matrix(~ 0 + fit:maternalID, redata)
modmat.siredam <- cbind(modmat.sire, modmat.dam)
rout <- reaster(resp ~ fit + varb,
    list(parental=~0 + modmat.siredam, block = ~ 0 + fit:block),
    pred, fam, varb, id, root, data = redata)
```

Summary.
```{r summary.reaster.parents, cache=TRUE, depends="reaster.parents"}
summary(rout)
```

# With R Function Objfun

## Evaluate Reaster Solution

```{r objfun}
objfun <- objfun.factory(rout$fixed, rout$random, rout$response,
    pred, fam, rout$obj$root)
theta <- with(rout, c(alpha, b, nu))
objfun(theta)
```

```{r gradient.solution.reaster, cache=TRUE}
foo <- grad(objfun, theta)
foo
```

## Conventional Optimization

```{r nlm, cache=TRUE}
baz <- nlm(objfun, theta)
```

So is this better?
```{r nlm-results, cache=TRUE, dependson="nlm"}
names(baz)
theta.too <- baz$estimate
objfun(theta.too) - objfun(theta)
max(abs(theta.too - theta))
theta.too
baz$gradient
```

Still fairly big numbers for gradient, but maybe OK if much bigger numbers
for Hessian.
```{r nlm-hessian, cache=TRUE, dependson="nlm"}
baz <- nlm(objfun, theta.too, hessian = TRUE)
```

What have we got?
```{r nlm-hessian-check}
class(baz$hessian)
dim(baz$hessian)
eigen(baz$hessian, symmetric = TRUE, only.values = TRUE)$values
vinv <- .Call(aster:::C_pos_def_mat_inv, baz$hessian)
dim(vinv)
all(is.finite(vinv))
1 / eigen(vinv, symmetric = TRUE, only.values = TRUE)$values
```

# References


